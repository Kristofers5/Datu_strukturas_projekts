import requests
from bs4 import BeautifulSoup


class Node:
    def __init__(self, book, chapter, text):
        self.book = book
        self.chapter = chapter
        self.text = text
        self.next = None

class LinkedList:
    def __init__(self):
        self.head = None

    def append(self, book, chapter, text):
        new_node = Node(book, chapter, text)
        if not self.head:
            self.head = new_node
        else:
            current = self.head
            while current.next:
                current = current.next
            current.next = new_node

    def print(self):
        current = self.head
        while current:
            print(current.book, current.chapter, current.text)
            current = current.next






print("nodaļa vai grāmata")
funkcija = input()

if funkcija == "nodaļa":
    print("Ievadiet linku uz nodaļu:")
    adrese = input()
    print("Faila nosaukums:")
    faila_nosaukums = input()


    # piemēri
    # adrese = "https://www.royalroad.com/fiction/65058/pale-lights/chapter/1124855/chapter-1"
    #           https://www.royalroad.com/fiction/65058/pale-lights/chapter/2283890/chapter-6
    #           https://www.royalroad.com/fiction/21220/mother-of-learning/chapter/301778/1-good-morning-brother


    lapa = requests.get(adrese)
    if lapa.status_code == 200:
        lapas_saturs = BeautifulSoup(lapa.content, "html.parser")

        content_div = lapas_saturs.find("div", {"class": "chapter-content"})

        paragraphs = content_div.find_all("p")


        # test print

        # for line in paragraphs:
        #     print(line.contents)

        try:
            f = open(f"{faila_nosaukums}.txt", "x")
        except:
            print("file already exists")

        with open(f"{faila_nosaukums}.txt", "w") as f:
            f.write(f"{faila_nosaukums}\n\n\n\n")

            for line in paragraphs:
                f.write(line.get_text())
                f.write("\n\n")


elif funkcija == "grāmata":
    
    adrese = "https://practicalguidetoevil.wordpress.com/table-of-contents/"

    lapa = requests.get(adrese)

    if lapa.status_code == 200:
        lapas_saturs = BeautifulSoup(lapa.content, "html.parser")

        ul_div = lapas_saturs.find_all("ul")


        # prints only links to chapters in book 1
        # for line in ul_div[1]:
        #     print(line)


        gramatu_serija = LinkedList()

        n = 1
        book = 1

        try:
            f = open("PGtE.txt", "x")
        except:
            print("file already exists")

        with open("PGtE.txt", "a") as f:
            while n <= 8:

                for li in ul_div[n].find_all('li'):

                    text = ""
                    if n == 2:
                        break
                    
                    a = li.find('a')
                    if a:
                        link = a.get('href')
                        

                    adrese = link
                    lapa = requests.get(adrese)
                    if lapa.status_code == 200:
                        lapas_saturs = BeautifulSoup(lapa.content, "html.parser")

                        content_div = lapas_saturs.find("div", {"class": "entry-content"})

                        paragraphs = content_div.find_all("p")

                        f.write("\n\n\n\n")

                        for line in paragraphs:
                            f.write(line.get_text())
                            f.write("\n\n")

                            text = text + line.get_text() + " "

                    chapter_name = li.getText()
                    
                    # print(text)

                    gramatu_serija.append((f"Book {book}"), (f"{chapter_name}"), (f" {text}"))


                n = n + 1
                if n == 2:
                    continue
                else:
                    book = book + 1


        gramatu_serija.print()


else:
    print("Kļūda, nepareiza komanda!")
    exit()