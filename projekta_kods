import requests
from bs4 import BeautifulSoup

print("nodaļa vai grāmata")
funkcija = input()

if funkcija == "nodaļa":
    print("Ievadiet linku uz nodaļu:")
    adrese = input()
    print("Faila nosaukums:")
    faila_nosaukums = input()


    # piemēri
    # adrese = "https://www.royalroad.com/fiction/65058/pale-lights/chapter/1124855/chapter-1"
    #           https://www.royalroad.com/fiction/65058/pale-lights/chapter/2283890/chapter-6
    #           https://www.royalroad.com/fiction/21220/mother-of-learning/chapter/301778/1-good-morning-brother


    lapa = requests.get(adrese)
    if lapa.status_code == 200:
        lapas_saturs = BeautifulSoup(lapa.content, "html.parser")

        content_div = lapas_saturs.find("div", {"class": "chapter-content"})

        paragraphs = content_div.find_all("p")


        # test print

        # for line in paragraphs:
        #     print(line.contents)

        try:
            f = open(f"{faila_nosaukums}.txt", "x")
        except:
            print("file already exists")

        with open(f"{faila_nosaukums}.txt", "w") as f:
            f.write(f"{faila_nosaukums}\n\n\n\n")

            for line in paragraphs:
                f.write(line.get_text())
                f.write("\n\n")

elif funkcija == "grāmata":
    
    adrese = "https://practicalguidetoevil.wordpress.com/table-of-contents/"

    lapa = requests.get(adrese)

    if lapa.status_code == 200:
        lapas_saturs = BeautifulSoup(lapa.content, "html.parser")




    exit()


else:
    print("error")
    exit()